{"componentChunkName":"component---src-templates-blog-post-js","path":"/4_ICL_Mathis/","result":{"data":{"site":{"siteMetadata":{"title":"Edouard Koehn"}},"markdownRemark":{"id":"7f700bb7-5f85-5534-b779-4c6730c82b4a","excerpt":"Transformer models have revolutionized the scientific landscape, rapidly surpassing traditional architectures across fields like computer vision, natural…","html":"<p>Transformer models have revolutionized the scientific landscape, rapidly surpassing traditional architectures across fields like computer vision, natural language processing (NLP), and audio processing.</p>\n<p>This architecture enables scaling up the data available to models during training, resulting in emergent behaviors. One such behavior is in-context learning (ICL) (<a href=\"https://arxiv.org/pdf/2005.14165\">Brown et al., 2020</a>). ICL allows models to address new tasks by integrating task demonstrations directly into the prompt, eliminating the need for fine-tuning.</p>\n<p>Recently, ICL has been extended beyond NLP to other fields, such as <a href=\"https://arxiv.org/pdf/2308.08536\">dynamical systems prediction</a>. Meanwhile, Transformer-based models have also shown promising results in <a href=\"https://arxiv.org/pdf/2106.01345\">reinforcement learning setups</a>.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/edouardkoehn.github.io/static/b9aa0058bf2c0d2eccf01361047ee449/3ceac/img_0.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.77215189873418%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAABwElEQVR42kWRW4/SUBSF+6eN8UF/gIlvJsZxEh9NjL4aTZwQBDJFEAahZQplgA4GOgXKQG+nt8/TM152snL2Wnut3fZUoywpoy1EO4j3f+BL/l8ri4yqSuktiqKKqMplj8j5MKuhu6bSNJFmCOMjRe0xef0pRf0Zee0Jhf5cIb94RDZ8p8y2H/Dd2ZEJuVTy4/GICAK+OFOuD+7DwmoQ37uEdp34pkGyaBFOa/gznfubNuHkgvi2o8w1Z83rmsWnz3PSOCUSKc5qje967L0dgVyuyQ9huRec/Yg470W8vUp41Qk4b604a97ysn3ivZkSJBmng4/nbdnKcBgJ/EWPtfGNu92ezWZNcDqhZangECT0VwGDXyE/JXqyt7wYy42kHnK19ImTlH9V5urwWm9Yf31BIqkQCVmWoYVhSAV58xRZKr2ZbOVZ5BRVL5FEoXp6mqYyKBRK+UOiOMa2Z7iuy3w+x/d9tOVyyXg8ZmrbmONrDMNkZBhYkwmjkaE0y5oojylnpvkAW/orbTgcyozBYDBgsVigTWSw0WjQ7/dpt9sKnU5H8cvLS7rdruJ/9WazqcLVXNd1Na9eynEceY8bfgP7N0o1CufL4wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Alt text\"\n        title=\"\"\n        src=\"/edouardkoehn.github.io/static/b9aa0058bf2c0d2eccf01361047ee449/f058b/img_0.png\"\n        srcset=\"/edouardkoehn.github.io/static/b9aa0058bf2c0d2eccf01361047ee449/c26ae/img_0.png 158w,\n/edouardkoehn.github.io/static/b9aa0058bf2c0d2eccf01361047ee449/6bdcf/img_0.png 315w,\n/edouardkoehn.github.io/static/b9aa0058bf2c0d2eccf01361047ee449/f058b/img_0.png 630w,\n/edouardkoehn.github.io/static/b9aa0058bf2c0d2eccf01361047ee449/40601/img_0.png 945w,\n/edouardkoehn.github.io/static/b9aa0058bf2c0d2eccf01361047ee449/78612/img_0.png 1260w,\n/edouardkoehn.github.io/static/b9aa0058bf2c0d2eccf01361047ee449/3ceac/img_0.png 1456w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>In this project, we explore ICL for complex Markov Decision Processes (MDPs). Specifically, we investigate whether Transformer-based policies can extract relevant information from their context to solve locomotion tasks.</p>\n<h3><ins>Technical details</ins>:</h3>\n<p>We trained a GPT-2-based policy in a supervised manner using the <a href=\"https://www.gymlibrary.dev/index.html\">Open Gym framework</a>. During training, we exposed the model to a set of morphologies sampled from a specific perturbation space. This approach, inspired by the work of <a href=\"https://arxiv.org/pdf/2209.14218\">Chiappa et al.</a>, allowed us to test our policy under various perturbations, simulating the concept of new tasks in our setup.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/edouardkoehn.github.io/static/056704e017faa80e26227800ffb705ca/71ba4/img_3.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.405063291139236%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAAB3UlEQVR42m2STWsTURSG86tcu3ApdSOtIFi/EAW7UQQ3ilSwCq0mCC2UQq0uWhRLmpAsKqiLxCASNUmbohZSkmgzSSaTzFcmk5k8nkmbUtALL3Pv3DvvPe9zJqQ1Guz/+InTaB6pW2/Qdxz+N7rdLqZpYNsWnuf9sx/qfM+zN36ByvgkZVFl4iJ7YxOo6QyuHLBNE0fMfd9nMBhg6Aa6rlOtlIk8nWNxYZ5XL5Z5Hn7Gp1SKkC2b+zs71ER/8gVqxeJw3VIUbKnGc/u0NW1oFozR07IsYvEY0dgGiWSC1bVVcrkcIT2o8Mw5qpeuU7l8g+rVm5ROn0X/kqVjm3xIxNmMRXkXj5JNpzh0PYoYXODY9sFcUoQ8Q3h8zWHnt7ELovwWRvabZO1S2v3F/dtThGemeXj3FovhWWFnY1gmWk2hdP4KpVNjgmyS3RMnqT2aFUMB64u7fwzsKFarrrC5sU5y/Q3Jt6/JfHw/ZBk0JpCj1PHUJj1B4qsdfMEXUgtbFK9NUX4wgxaep37nHlrmM6brYskBRz5syp8wusSV98G6IVI1FdXsk94uYpjKQZfd6m/akQU6Syu0l17SehLGlNhBh3tBFdLhnigwHBxj5x/O11J15mIRllceDw3/As0bN3tob0HgAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Alt text\"\n        title=\"\"\n        src=\"/edouardkoehn.github.io/static/056704e017faa80e26227800ffb705ca/f058b/img_3.png\"\n        srcset=\"/edouardkoehn.github.io/static/056704e017faa80e26227800ffb705ca/c26ae/img_3.png 158w,\n/edouardkoehn.github.io/static/056704e017faa80e26227800ffb705ca/6bdcf/img_3.png 315w,\n/edouardkoehn.github.io/static/056704e017faa80e26227800ffb705ca/f058b/img_3.png 630w,\n/edouardkoehn.github.io/static/056704e017faa80e26227800ffb705ca/40601/img_3.png 945w,\n/edouardkoehn.github.io/static/056704e017faa80e26227800ffb705ca/78612/img_3.png 1260w,\n/edouardkoehn.github.io/static/056704e017faa80e26227800ffb705ca/71ba4/img_3.png 1870w\"\n        sizes=\"(max-width: 630px) 100vw, 630px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h3><ins>References</ins>:</h3>\n<ul>\n<li><a href=\"https://arxiv.org/pdf/2209.14218\">A. S. Chiappa, A. M. Vargas, and A. Mathis, “DMAP: A Distributed Morphological Attention Policy for Learning to Locomote with a Changing Body”</a></li>\n<li><a href=\"https://arxiv.org/pdf/1706.03762\">A. Vaswani et al., “Attention is All You Need”</a></li>\n<li><a href=\"http://arxiv.org/abs/2306.14892\">J. N. Lee et al., “Supervised Pretraining Can Learn In-Context Reinforcement Learning”</a></li>\n<li><a href=\"http://arxiv.org/abs/2308.08536\">H. Balim, Z. Du, S. Oymak, and N. Ozay, “Can Transformers Learn Optimal Filtering for Unknown Systems?”</a></li>\n</ul>\n<h3><ins>Supervision</ins>:</h3>\n<ul>\n<li>Alberto Chiappa - EPFL</li>\n<li>Adriana Rotondo - EPFL</li>\n</ul>","frontmatter":{"title":"In-Context Learning for Locomotion - Mathis Group - EPFL","date":"June 28, 2024","description":null,"keywords":["Transformers - ","Reinforcement learning "],"github_link":"https://github.com/edouardkoehn/WM_Atlas"}},"previous":{"fields":{"slug":"/5_GRaph_MIPLAB/"},"frontmatter":{"title":"Brain White Matter Atlas - MIPLAB - EPFL"}},"next":null},"pageContext":{"id":"7f700bb7-5f85-5534-b779-4c6730c82b4a","previousPostId":"d3a8303a-596c-582f-bfec-0c418d0fb2fc","nextPostId":null}},"staticQueryHashes":["2841359383","3257411868"],"slicesMap":{}}